Welcome to adobo's documentation!
#################################

What adobo is
*************
adobo is an analysis framework for single cell RNA sequencing data (scRNA-seq) and enables exploratory analysis through a set of Python modules. adobo can be used to compose scripts, used in interactive workflows and much more. The goal of adobo is to consolidate single cell computational analysis methods in the Python programming language.

adobo is developed by Oscar FranzÃ©n (limited support is available over e-mail: p.oscar.franzen@gmail.com).

.. note::

   adobo is developed and tested on Python version 3.6.8; older versions may work but are untested.

Installation
============
The recommended way to install adobo is to first clone the GitHub repository and then use ``pip3`` from your terminal, which will also install the necessary dependencies:

.. code-block:: bash

   $ git clone https://github.com/oscar-franzen/adobo.git
   
   $ cd adobo
   
   $ pip3 install .
   
   $ # below installs adobo without package dependencies (not recommended)
   $ pip3 install --no-deps .

After installing it, you can now delete the cloned repository and test that everything works by firing up your Python 3 interpreter:

.. code-block:: bash

   $ python3

Try importing the library and it should greet you with the current version and the URL to the documentation (this page):

>>> import adobo as ad
adobo version 0.1. Documentation: https://oscar-franzen.github.io/adobo/

.. note::

   Support for ``PyPI`` is on the TODO list.

Package organization
====================
adobo is organized into several modules containing related functions. All module and function names are lowercase to make them easier to remember.

.. list-table::
   :header-rows: 1
   
   * - Module name
     - Function content
   * - ``preproc``
     - data preprocessing
   * - ``data``
     - the data container class
   * - ``dr``
     - dimensional reduction
   * - ``hvg``
     - highly varianble gene discovery
   * - ``normalize``
     - normalization of raw read counts
   * - ``IO``
     - reading and writing data (input/output)
   * - ``clustering``
     - functions related to data clustering operations
   * - ``plotting``
     - data visualization
   * - ``bio``
     - functions related to biology, for example cell cycle prediction
   * - ``stats``
     - miscellaneous or general statistical functions that don't fit anywhere else

Internal modules
^^^^^^^^^^^^^^^^
These do not need to be accessed but are listed here for documentation purposes.

.. list-table::
   :header-rows: 1

   * - Module name
     - Function content
   * - ``_colors``
     - related to color generation
   * - ``_log``
     - internal utilities
   * - ``_constants``
     - internal constants

Getting started and pre-processing your data
============================================
Loading the package
^^^^^^^^^^^^^^^^^^^
The first step is to load the adobo package by importing it:

.. code-block:: python3

   import adobo as ad

.. note::
   Debug information in the form of traceback output is suppressed by default. However, this information is often useful when trying to solve program bugs. To enable full traceback set:
   
   ``ad.debug=1``

Loading your data from a text file
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
First we need to create a new adobo object, which is an instance of the class :py:class:`adobo.data.dataset`. This will be a new object containing your single cell data as well as meta data. The input file should be a gene expression matrix (rows as genes and cells as columns) in plain text format. Fields can be separated by any character (default is tab) and it can be changed with the ``sep`` argument. The data matrix file can have a header or not (``header=0`` indicates a header is present, otherwise use ``header=None``). If the header of your gene expression matrix contains a label for gene symbols, set ``column_id='yes'`` or simply ``column_id='auto'`` to autodetect this. :py:func:`adobo.IO.load_from_file` calls :py:func:`pandas.DataFrame.read_csv` and any additional arguments are passed into this function. The function :py:func:`adobo.IO.load_from_file` is used to load data from a raw read count matrix and the returned object is an instance of :class:`adobo.data.dataset`:

.. code-block:: python3

   exp = ad.IO.load_from_file('GSE95315.tab', column_id='auto', desc='mouse brain data')

Here we use data from `GEO95315 <https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE95315>`_, which can be `downloaded here <https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE95315&format=file&file=GSE95315%5F10X%5Fexpression%5Fdata%2Etab%2Egz>`_.

``desc`` can be used to specify a string describing the data, but it can also be left empty.

.. important::

   The loaded data must **not** be normalized, i.e. it should be raw read counts.

.. note::

   All downstream operations and analyses are performed and stored as attributes in the adobo object, i.e. functions are applied on this object.

.. note::

   Many adobo functions also have a ``verbose`` argument, which when ``True`` makes the function more informative.

Creating the data class object directly from a pandas data frame
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
In many cases we already have our data in a pandas data frame, in those cases we can just create the container object directly:

.. code-block:: python3
 
   # where 'df' is the data frame, columns are cells and rows are genes
   exp = ad.dataset(df)

Saving object
^^^^^^^^^^^^^
Saving an object is done via the standard ``joblib`` package:

.. code-block:: python3

   import joblib
   joblib.dump(exp, 'test.joblib')
   exp = joblib.load('test.joblib')

Instead of writing three lines of code and always remembering the name of the output file, we can specify `output_filename` in :py:func:`adobo.IO.load_from_file` and then calling :py:func:`adobo.data.dataset.save()`.

Accessing meta data for cells and genes
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Meta data are stored in the adobo object (an instance of :py:class:`adobo.data.dataset`). Two data structures (instances of :class:`pandas.DataFrame`) hold meta data for cells and genes, respectively:

>>> exp.meta_cells
                      total_reads status  detected_genes   mito  ERCC  rRNA
EXP1_COL01_ROW01_S1          5935     OK             426   1455     2     0
EXP1_COL01_ROW02_S1          3036     OK             464   1583     0     0
EXP1_COL01_ROW03_S1         38477     OK            1961  20935     7     4
EXP1_COL01_ROW04_S1         63962     OK            3478   4463     7     0
EXP1_COL01_ROW05_S1          1885     OK             993    127     0     0
...                           ...    ...             ...    ...   ...   ...
EXP1_COL20_ROW36_S20        43051     OK            3277   4975    29     0
EXP1_COL20_ROW37_S20       162617     OK            4224  54144    55     0
EXP1_COL20_ROW38_S20        56649     OK            3281   4223    31     0
EXP1_COL20_ROW39_S20         3367     OK             927   1352     0     0
EXP1_COL20_ROW40_S20          422     OK             294     75     0     0
[800 rows x 6 columns]

>>> exp.meta_genes
                      expressed  expressed_perc status  mitochondrial   ERCC   rRNA
ENSMUSG00000102693.1          0         0.00000     OK          False  False  False
ENSMUSG00000064842.1          0         0.00000     OK          False  False  False
ENSMUSG00000051951.5          0         0.00000     OK          False  False  False
ENSMUSG00000102851.1          0         0.00000     OK          False  False  False
ENSMUSG00000103377.1          1         0.00125     OK          False  False  False
...                         ...             ...    ...            ...    ...    ...
ERCC-00164                  145         0.18125     OK          False   True  False
ERCC-00165                   25         0.03125     OK          False   True  False
ERCC-00168                  123         0.15375     OK          False   True  False
ERCC-00170                   91         0.11375     OK          False   True  False
ERCC-00171                   32         0.04000     OK          False   True  False
[45884 rows x 6 columns]

Adding meta data
^^^^^^^^^^^^^^^^
New meta data such as experimental factors can easily be added to your adobo object by calling :py:func:`adobo.data.dataset.add_meta_data`, which takes three parameters:

1. ``axis`` can be either 'cells' or 'genes'
2. the ``key`` is used as variable name
3. ``data`` should be a ``list`` containing your data with the same length as your dimension

Getting detailed help
^^^^^^^^^^^^^^^^^^^^^
All functions in adobo have extensive documentation, which are accessible as docstrings on the Python interactive console as well as online:

.. code-block:: python3

   help(ad)
   help(ad.IO.load_from_file)


Loading compressed data
^^^^^^^^^^^^^^^^^^^^^^^
scRNA-seq is zero inflated, and therefore compress strongly. We can load the compressed data directly without having to uncompress it first; the compression format is detected automatically (gzip, bz2, zip and xz are supported). For example:

.. code-block:: python3

   exp = ad.IO.load_from_file('GSE95315.tab.gz', column_id='auto')

Your gene expression data is stored in the attribute ``exp.exp_mat``, and after loading it is good practise to examine that the data were loaded properly:

>>> exp
53,889 genes and 384 cells were loaded

Data examination
^^^^^^^^^^^^^^^^
It's can be useful to examine number of reads per cell in a bar plot format:

.. code-block:: python3

   ad.plotting.reads_per_cell(exp)

Which will generate the plot:

.. image:: 2019-08-30-131424_587x441_scrot.png

It is also a good idea to examine number of expressed genes per cell:

.. code-block:: python3

   ad.plotting.genes_per_cell(exp)

.. image:: 2019-08-30-131930_594x451_scrot.png

Detecting ERCC spikes
^^^^^^^^^^^^^^^^^^^^^
ERCC are known amounts of synthetic constructs added to RNA-seq libraries for quality control and normalization purposes :cite:`Jiang2011`. Not all experiments use ERCC spikes, but many do. The ERCC "genes" are usually prefixed with `ERCC-` in the gene expression matrix. This function is used to flag them so that they are not included in downstream analyses.

.. note::

   The ``ERCC_pattern`` argument can be used to set a regular expression for identifying the ERCC features.

The :py:func:`adobo.preproc.detect_ercc_spikes` is used to filter out the ERCC (stored in :py:attr:`adobo.data.dataset.exp_ercc`):

.. code-block:: python3

   ad.preproc.detect_ercc_spikes(exp)

Detecting mitochondrial genes
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
It's often a good idea not to include the mitochondrial genes in the analysis and some downstream analyses require that adobo knows which genes are mitochondrial. Usually the mitochondrial genes in human and mouse genomes have gene symbols starting with the prefix ``mt-``, but this might vary from species to species.

.. code-block:: python3

   ad.preproc.find_mitochondrial_genes(exp)

Or specify a custom regular expression to identify them:

.. code-block:: python3

   ad.preproc.find_mitochondrial_genes(exp, mito_pattern='^mito-')

Sometimes mitochondrial genes don't start with a certain prefix and it is better to set these genes with a single function:

.. code-block:: python3

   ad.preproc.set_mitochondrial_genes(exp, genes=['geneA','geneB','geneC'])

Applying simple filters
^^^^^^^^^^^^^^^^^^^^^^^
Simple filters refers to applying a strict minimum cutoff on the number of expressed genes per cell and the total read depth per cell. Simple filters are usually effective in removing low quality cells and uninformative genes. If your data come from Drop-seq, 10X, etc, requiring at least 1000 uniquely mapped reads per cell is often sufficient:

.. code-block:: python3

   ad.preproc.simple_filter(exp, minreads=1000, minexpgenes=0.001)

.. important::

   If your protocol is applying full-length mRNA sequencing, e.g. SMART-seq2, then your ``minreads`` threshold should be higher, for example 10000.

.. note::

   :py:func:`adobo.preproc.simple_filter` also has a `maxreads` parameter, which can be used to remove cells with an upper read count limit (perhaps useful for limiting doublets). However, this parameter is not set by default.

It is also desirable to remove genes with an expression signal in very few cells; such genes may contribute more noise than information. The ``minexpgenes`` argument can be used to control how genes are filtered out. If you wish to not remove any genes at all, simply set it to zero:

.. code-block:: python3

   ad.preproc.simple_filter(exp, minreads=1000, minexpgenes=0)

Setting ``minexpgenes`` to a fraction indicates that at least that fraction of cells must express any gene. If ``minexpgenes`` is an integer it refers to the absolute number of cells that at minimum must express the gene for the gene not to be filtered out.

To reset all simple filters to original:

.. code-block:: python3

   exp.reset_filters()

Automatic detection of low quality cells
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
A more sophisticated approach to detection of low quality cells is to use the function :py:func:`adobo.preproc.find_low_quality_cells`, which uses `Mahalanobis distance`_ to identify bad cells from five quality metrics.

.. important::

   ``find_low_quality_cells`` requires that there are ERCC spikes in your data.

The argument ``rRNA_genes`` should either be a string containing the full path to a file on disk contaiing genes that are rRNA genes (the file should have one gene per line). ``rRNA_genes`` can also be a :py:class:`pandas.Series` object with gene symbols.

.. code-block:: python3

   ad.preproc.find_low_quality_cells(exp, rRNA_genes=rRNA)

Like all adobo functions, ``find_low_quality_cells`` modifies the passed object. However, ``find_low_quality_cells`` also returns a list of cells that are classified as low quality; to prevent such behavior simply assign the return to a variable:

.. code-block:: python3

   low_q_cells = ad.preproc.find_low_quality_cells(exp, rRNA_genes=rRNA)

Normalization
=============
Normalization removes technical and sometimes experimental biases and is always necessary prior to analysis. Because a single normalization scheme for scRNA-seq data is not available, adobo supports several different procedures. The function :py:func:`adobo.normalize.norm` can be used to perform the following normalization methods:

**standard**
   Performs a standard normalization by scaling with the total read depth per cell and then multiplying with a scaling factor.

**rpkm**
   Normalizes read counts as Reads per kilo base per million mapped reads (RPKM) :cite:`Conesa2016`. This method should be used if you need to adjust for gene length, such as in a SMART-Seq2 protocol. To use this procedure you must first prepare a file containing combined exon lengths for genes; the file should contain two columns, **without a header**, and columns separated by one space. The following columns must be present: (1) gene symbols and (2) the sum of exon lengths. The filename is set with the ``gene_lengths`` parameter, which can also take a vector.

**fqn**
   Performs full quantile normalization :cite:`Bolstad2003`. FQN was a popular normalization scheme for microarray data. It is not very common in single cell analysis despite having been shown to perform well :cite:`Cole2018`. The present implementation does not handle ties well.

**clr**
   Centered log ratio normalization. This normalization scheme was introduced in Seurat version 3.0 :cite:`Stuart2018`. It is a simple normalization scheme and is an alternative to ``standard``.

**vsn**
   Variance stabilizing normaliztion based on a negative binomial regression model with regularized parameters. Introduced by :cite:`Hafemeister2019` and represents the most complex scheme of the above; appears to marginally improve resolution.

All normalization schemes, except ``vsn``, can be followed by log (base 2) transformation (set by the ``log2=True`` flag, which is enabled by default).

To perform a ``standard`` normalization followed by ``log2`` transformation, run:

.. code-block:: python3

   ad.normalize.norm(exp, method='standard')

The normalized data are stored in the attribute :py:attr:`adobo.data.dataset.norm`.

.. note::

   If you have previously executed :py:func:`adobo.preproc.detect_ercc_spikes`, ERCC spikes will be normalized too, and these can be found in :py:attr:`adobo.data.dataset.norm_ercc`.

Examining analysis history
==========================
Downstream analyses are performed on the data object. At any time it's possible to examine what functions have been applied on data object by calling :py:func:`adobo.data.dataset.assays`:

>>> exp.assays()
Number of mitochondrial genes found: 0
Number of ERCC spikes found: 92 
Normalization method: <not performed yet> 
Has HVG discovery been performed? No

Detection of highly variable genes
==================================
Most algorithms used in scRNA-seq analysis performs better when performed on only a subset of measured genes :cite:`Yip2018`; the goal of the feature selection step is usually to extract a set highly variable genes (HVG). adobo currently implements the following strategies for HVG discovery:

**seurat** 
    The function bins the genes according to average expression, then calculates dispersion for each bin as variance to mean ratio. Within each bin, Z-scores are calculated and returned. Z-scores are ranked and the top 1000 are selected. Input data should be normalized first. This strategy was introduced in Seruat :cite:`Stuart2018`, it is simple yet highly effective in identifying HVG.

**brennecke**
    Implements the method described in :cite:`Brennecke2013`. ``brennecke`` estimates and fits technical noise using ERCC spikes (technical genes) by fitting a generalized linear model with a gamma function and identity link and the parameterization w=a_1+u+a0. It then uses the chi2 distribution to test the null hypothesis that the squared coefficient of variation does not exceed a certain minimum. False discovery rate (FDR)<0.10 is considered significant.

**scran**
    scran fits a polynomial regression model to technical noise by modeling the variance versus mean gene expression relationship of ERCC spikes (the original method used local regression) :cite:`Lun2016`. It then decomposes the variance of the biological gene by subtracting the technical variance component and returning the biological variance component.

**chen2016**
    This method uses linear regression, subsampling, polynomial fitting and gaussian maximum likelihood estimates to derive a set of HVG :cite:`Chen2016`.

**mm**
    Selection of HVG by modeling dropout rates using modified Michaelis-Menten kinetics :cite:`Andrews2018`. This method calculates dropout rates and mean expression for every gene, then models these with the Michaelis-Menten equation (parameters are estimated with maximum likelihood optimization). The basis for using MM is because most dropouts are caused by failure of the enzyme reverse transcriptase, thus the dropout rate can be modelled with theory developed for enzyme reactions. This implementation works best for libraries sequenced to saturation (i.e. not Drop-seq).

Example:

.. code-block:: python3

   ad.hvg.find_hvg(exp, method='seurat')

The results are stored in :py:attr:`adobo.data.dataset.hvg`.

Dimensional reduction
=====================
These are techniques to reduce the number of dimensions under consideration. After running these functions, results are stored in the ``dict`` :py:attr:`adobo.data.dataset.dr`.

Principal Component analysis (PCA)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
PCA decomposition :cite:`Abdi2010` of single cell data is for the most part necessary prior to clustering. The reason for this is because the graph construction benefits from a strong signal from each feature. PCA computation in adobo is performed by invoking :py:func:`adobo.dr.pca()`. Scaling of the data should always be done before PCA, and this is done by default (although it can be turned off by setting ``scale=False``). Two approaches are available for PCA decomposition, and it should not matter much which one is used:

**irlb**
    Computed via truncated singular value decomposition by implicitly restarted Lanczos bidiagonalization :cite:`Baglama2005`. `irlb` may be better at handling very large single cell datasets and it is the default.

**svd**
    Computed via singular value decomposition. (More likely to raise ``MemoryError``.)

Examples:

.. code-block:: python3

   ad.dr.pca(exp)
   ad.dr.pca(exp, method='svd')

.. note::

   PCA components are stored in the dictionary :py:attr:`adobo.data.dataset.dr` and variable contributions are stored in the dictionary :py:attr:`adobo.data.dataset.dr_gene_contr`.

We can now examine the top contributing genes to each PCA component by producing a plot with :py:func:`adobo.plotting.pca_contributors`.

To plot the top 10 contributing genes to the first five components:

.. code-block:: python3

   ad.plotting.pca_contributors(exp, dim=range(0,5), top=10)

.. image:: pca_contributors.png

We can also write the output to a file instead of showing it on the screen:

.. code-block:: python3

   ad.plotting.pca_contributors(exp, dim=range(0,5), top=10, filename='top_pca_genes.pdf')

t-Distributed Stochastic Neighbor Embedding (t-SNE)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
t-SNE :cite:`vanDerMaaten2008` is the *de facto* dimensional reduction technique used to visualize scRNA-seq data :cite:`Kobak2019`. adobo uses the scikit-learn implementation :cite:`Pedregosa2011`. Any additional parameters will be passed into :py:class:`sklearn.manifold.TSNE`. By default adobo runs t-SNE on the PCA decomposition:

.. code-block:: python3

   ad.dr.tsne(exp, perplexity=10)

Run it on your entire normalized expression matrix (not recommended):

.. code-block:: python3

   ad.dr.tsne(exp, target='norm', verbose=True)

Uniform Manifold Approximation and Projection (UMAP)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UMAP :cite:`McInnes2018` is also used frequently to visualize scRNA-seq data, and it may be better at preserving the global structure of the data:

.. code-block:: python3

   ad.dr.umap(exp)

.. toctree::
   :maxdepth: 2
   :caption: Contents:

Clustering
==========
A crucial step in scRNA-seq analysis is to group cells into clusters. Complex datasets consisting of thousands of cells can be reduced to a small number of clusters, which tend to be easier to analyze and interpret.

.. important::

   Clustering is performed in PCA space, therefore PCA components must have been calculated first using :py:func:`adobo.dr.pca`.

In adobo, clustering can be performed with a single line of code:

.. code-block:: python3

   # to run leiden
   ad.clustering.generate(exp, res=0.8, method='leiden')
   
   # to run walktrap
   ad.clustering.generate(exp, clust_alg='walktrap')

The above command will run the necessary steps to cluster your single cell dataset; the cluster membership vector is stored in :py:attr:`adobo.data.dataset.clusters`, i.e. represented by an array with the same length as the number of cells after pre-processing. adobo's default clustering algorithm first builds a Shared Nearest Neighbor graph :cite:`Ertoz2003` and then finds communities in this graph using the Leiden algorithm :cite:`Traag2019` (default). It may become necessary to change value of the ``res`` (resolution) parameter to find the optimal clustering outcome.

Other community detection algorithms are also supported via the `igraph <https://igraph.org/redirect.html>`_ package:

* ``walktrap`` :cite:`Pons2006`
* ``spinglass`` :cite:`Reichardt2006`
* ``multilevel`` :cite:`Blondel2008`
* ``infomap`` :cite:`Rosvall2008`
* ``label_prop`` (label propagation) :cite:`Raghavan2007`
* ``leading_eigenvector`` (Newman's leading eigenvector method) :cite:`Newman2006`

Various parameters of the these algorithms can be changed in :py:func:`adobo.clustering.generate`.

.. note::

   ``spinglass`` does not scale well on large datasets :cite:`Yang2016`.

Clustering visualization
========================
Visualization of cells in 2d space is performed with the function :py:func:`adobo.plotting.cell_viz`. Before running ``cell_viz``, the appropriate reduction functions must have been invoked first. The parameter ``what_to_color`` is used to control what will be colored. The default value is 'clusters', which colors by cluster; other options are: 'nothing' which colors all cells black; a third option is to specify a variable listed as meta data in :py:attr:`adobo.data.dataset.meta_cells` (added via :py:func:`adobo.data.dataset.add_meta_data`).

Examples:

.. code-block:: python3

   # tsne
   ad.plotting.cell_viz(exp, reduction='tsne')
   
   # umap
   ad.plotting.cell_viz(exp, reduction='umap')
   
   # tsne and assign random colors to clusters
   ad.plotting.cell_viz(exp, reduction='tsne', colors='random')
   
Cell cycle prediction
=====================
It is often useful to get an understanding of the cell cycle state in a new data set. adobo contains a classifier based on the sklearn implementation of `Stochastic Gradient Descent <https://en.wikipedia.org/wiki/Stochastic_gradient_descent>`_. The classifier is trained on mouse embryonic stem cells (n=288 cells) :cite:`Buettner2015`. The original data can be retrieved from `here <https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-2805/>`_. Cell cycle classification is performed by calling two functions:

.. code-block:: python3

   # trains the classifier
   clf, tr_features = ad.bio.cell_cycle_train()
   
   # performs the actual classification of cells in your data
   ad.bio.cell_cycle_predict(obj, clf, tr_features)

Classification is stored in `obj.meta_cells['cell_cycle']`. The current design does not support prediction scores, although this can easily be changed by changing the `loss parameter <https://scikit-learn.org/stable/modules/sgd.html>`_.

.. important::

   Prediction is only valid on mouse data since the classifier is trained on mouse data; gene identifiers will only match mouse. Make sure your gene expression contains Ensembl gene identifiers.

Indices and tables
==================

* :ref:`genindex`
* :ref:`modindex`

.. _scRNA-seq: https://en.wikipedia.org/wiki/Single_cell_sequencing
.. _Mahalanobis distance: https://en.wikipedia.org/wiki/Mahalanobis_distance

References
==========
.. bibliography:: references.bib
   :style: unsrt
